{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÃºmero de registros obtenidos: 262314\n",
      "DataFrame creado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "db_path = os.path.join('..', 'database', 'smite_players.db')\n",
    "conn = sqlite3.connect(db_path)\n",
    "c = conn.cursor()\n",
    "\n",
    "# Execute a query to retrieve all records\n",
    "c.execute(\"SELECT * FROM combined_data5\")\n",
    "\n",
    "# Get the column names\n",
    "column_names = [description[0] for description in c.description]\n",
    "\n",
    "# Fetch all the results\n",
    "rows = c.fetchall()\n",
    "\n",
    "# Check if there are any results\n",
    "print(f\"Number of records retrieved: {len(rows)}\")\n",
    "\n",
    "# Convert the results into a pandas DataFrame\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "    print(\"DataFrame created successfully.\")\n",
    "else:\n",
    "    print(\"No records found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying differents models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\520493886.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['build_score'] = df['damage']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Function to split and ensure each list has 3 elements\n",
    "def split_tags(tags):\n",
    "    split = tags.split(', ') if pd.notna(tags) else [None, None, None]\n",
    "    while len(split) < 3:\n",
    "        split.append(None)\n",
    "    return split[:3]\n",
    "\n",
    "# Step 1: Split the tag columns into 3 components\n",
    "df[['character_tag_1', 'character_tag_2', 'character_tag_3']] = pd.DataFrame(df['character_tags'].apply(split_tags).tolist(), index=df.index)\n",
    "df[['enemy_1_tag_1', 'enemy_1_tag_2', 'enemy_1_tag_3']] = pd.DataFrame(df['enemy_1_tags'].apply(split_tags).tolist(), index=df.index)\n",
    "df[['enemy_2_tag_1', 'enemy_2_tag_2', 'enemy_2_tag_3']] = pd.DataFrame(df['enemy_2_tags'].apply(split_tags).tolist(), index=df.index)\n",
    "df[['enemy_3_tag_1', 'enemy_3_tag_2', 'enemy_3_tag_3']] = pd.DataFrame(df['enemy_3_tags'].apply(split_tags).tolist(), index=df.index)\n",
    "\n",
    "# Step 2: Encode categorical variables\n",
    "categorical_columns = [\n",
    "    'character_name', 'enemy_1_character', 'enemy_2_character', 'enemy_3_character',\n",
    "    'character_class_distance', 'character_type_dmg', 'character_type_dmgform',\n",
    "    'character_tag_1', 'character_tag_2', 'character_tag_3',  \n",
    "    'enemy_1_class_distance', 'enemy_1_type_dmg', 'enemy_1_type_dmgform',\n",
    "    'enemy_1_tag_1', 'enemy_1_tag_2', 'enemy_1_tag_3',  \n",
    "    'enemy_2_class_distance', 'enemy_2_type_dmg', 'enemy_2_type_dmgform',\n",
    "    'enemy_2_tag_1', 'enemy_2_tag_2', 'enemy_2_tag_3',  \n",
    "    'enemy_3_class_distance', 'enemy_3_type_dmg', 'enemy_3_type_dmgform',\n",
    "    'enemy_3_tag_1', 'enemy_3_tag_2', 'enemy_3_tag_3'\n",
    "]\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Read processed items from file\n",
    "with open(\"items_procesados.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    items_procesados = [line.strip() for line in file]\n",
    "\n",
    "# Step 1: Extract all unique items\n",
    "all_items = df['build'].str.split(', ').explode().unique()\n",
    "\n",
    "# Create binary columns only for permitted items\n",
    "for item in all_items:\n",
    "    df[item] = df['build'].apply(lambda x: 1 if item in x.split(', ') else 0)\n",
    "\n",
    "# Step 2: Define predictor variables (X) and target variable (y)\n",
    "X = df_encoded[df_encoded.columns[df_encoded.columns.str.startswith(tuple(categorical_columns))]]\n",
    "df['damage'] = pd.to_numeric(df['damage'].str.replace(',', ''), errors='coerce')\n",
    "df['damage_taken'] = pd.to_numeric(df['damage_taken'].str.replace(',', ''), errors='coerce')\n",
    "df['damage_mitigated'] = pd.to_numeric(df['damage_mitigated'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "# Calculate build score\n",
    "df['build_score'] = df['damage']\n",
    "\n",
    "build_columns = df.columns[df.columns.isin(all_items)]\n",
    "\n",
    "# Add build columns to predictor variables X\n",
    "X = pd.concat([X, df[build_columns]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 9668.4414 - val_loss: 5182.5298\n",
      "Epoch 2/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5507.1797 - val_loss: 5060.5449\n",
      "Epoch 3/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5412.6982 - val_loss: 5015.3843\n",
      "Epoch 4/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5387.4736 - val_loss: 4996.8696\n",
      "Epoch 5/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5293.3960 - val_loss: 4966.2363\n",
      "Epoch 6/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5303.4136 - val_loss: 4971.4683\n",
      "Epoch 7/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5292.2153 - val_loss: 4960.6138\n",
      "Epoch 8/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5239.3477 - val_loss: 4956.5552\n",
      "Epoch 9/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5221.4512 - val_loss: 5006.1143\n",
      "Epoch 10/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5235.0557 - val_loss: 4929.7549\n",
      "Epoch 11/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5195.5674 - val_loss: 4927.7041\n",
      "Epoch 12/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5217.6377 - val_loss: 4927.0933\n",
      "Epoch 13/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 5191.7114 - val_loss: 4914.3765\n",
      "Epoch 14/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5142.8462 - val_loss: 4911.0278\n",
      "Epoch 15/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 5164.2168 - val_loss: 4915.6626\n",
      "Epoch 16/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 5114.2661 - val_loss: 4900.4780\n",
      "Epoch 17/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 5133.4302 - val_loss: 4907.1636\n",
      "Epoch 18/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5110.2344 - val_loss: 4908.3335\n",
      "Epoch 19/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5096.9575 - val_loss: 4896.5527\n",
      "Epoch 20/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 5093.0752 - val_loss: 4921.0894\n",
      "Epoch 21/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5090.3071 - val_loss: 4901.1450\n",
      "Epoch 22/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 5082.6953 - val_loss: 4898.9341\n",
      "Epoch 23/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5047.2617 - val_loss: 4897.3311\n",
      "Epoch 24/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5036.5425 - val_loss: 4886.0142\n",
      "Epoch 25/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 5021.7119 - val_loss: 4891.9668\n",
      "Epoch 26/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 5028.8857 - val_loss: 4897.3911\n",
      "Epoch 27/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 5038.7075 - val_loss: 4895.9189\n",
      "Epoch 28/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 4980.0254 - val_loss: 4910.8516\n",
      "Epoch 29/100\n",
      "\u001b[1m6558/6558\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 4983.6279 - val_loss: 4902.7271\n",
      "\u001b[1m1640/1640\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 932us/step - loss: 4840.4976\n",
      "Test Loss (RMSE): 4886.01416015625\n",
      "Epoch 1/10\n",
      "\u001b[1m1640/1640\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5379.2866\n",
      "Epoch 2/10\n",
      "\u001b[1m1640/1640\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5327.8374\n",
      "Epoch 3/10\n",
      "\u001b[1m1640/1640\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5205.7109\n",
      "Epoch 4/10\n",
      "\u001b[1m1640/1640\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5182.3271\n",
      "Epoch 5/10\n",
      "\u001b[1m1640/1640\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5128.3926\n",
      "Epoch 6/10\n",
      "\u001b[1m1640/1640\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5066.5918\n",
      "Epoch 7/10\n",
      "\u001b[1m1640/1640\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5050.2993\n",
      "Epoch 8/10\n",
      "\u001b[1m1640/1640\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5078.0103\n",
      "Epoch 9/10\n",
      "\u001b[1m1640/1640\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4993.3823\n",
      "Epoch 10/10\n",
      "\u001b[1m1640/1640\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4991.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b4320d9be0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a custom loss function for RMSE using TensorFlow backend\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.keras.backend.sqrt(tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true)))\n",
    "\n",
    "# Assuming that the build encoding and the dataset X and the target variable 'build_score' are already prepared\n",
    "\n",
    "# Split into training and test set (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['build_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling (recommended for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the Neural Network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))  # Input layer\n",
    "model.add(BatchNormalization())  # Batch Normalization\n",
    "model.add(Dropout(0.5))  # Dropout to avoid overfitting\n",
    "model.add(Dense(64, activation='relu'))  # Second dense layer\n",
    "model.add(Dense(1, activation='linear'))  # Output layer (for regression)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=rmse)\n",
    "\n",
    "# Define early stopping (to stop training if no improvement)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss (RMSE): {test_loss}\")\n",
    "\n",
    "# Continue training the model with the test set\n",
    "model.fit(X_test, y_test, epochs=10, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save('nn_build_score_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-13 15:57:09,115] A new study created in memory with name: no-name-2aa2ac5c-53dd-475e-b73a-a7c23d7b9316\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 15:57:26,101] Trial 0 finished with value: 6348.636099331196 and parameters: {'iterations': 688, 'learning_rate': 0.004362539893743521, 'depth': 5, 'l2_leaf_reg': 3.6785580176922448, 'bagging_temperature': 0.04988310999057444}. Best is trial 0 with value: 6348.636099331196.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 15:57:54,591] Trial 1 finished with value: 5978.76707134543 and parameters: {'iterations': 856, 'learning_rate': 0.006788169013473108, 'depth': 7, 'l2_leaf_reg': 8.99372247907845, 'bagging_temperature': 0.7147870160999024}. Best is trial 1 with value: 5978.76707134543.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 15:59:11,562] Trial 2 finished with value: 5560.29322423045 and parameters: {'iterations': 1914, 'learning_rate': 0.009265891646513464, 'depth': 8, 'l2_leaf_reg': 8.014396305156026, 'bagging_temperature': 0.9562173884046219}. Best is trial 2 with value: 5560.29322423045.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:01:42,374] Trial 3 finished with value: 5806.5143039047225 and parameters: {'iterations': 1509, 'learning_rate': 0.004237492939420398, 'depth': 10, 'l2_leaf_reg': 7.769736943548668, 'bagging_temperature': 0.19037574625507692}. Best is trial 2 with value: 5560.29322423045.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:01:59,080] Trial 4 finished with value: 5412.338841835868 and parameters: {'iterations': 710, 'learning_rate': 0.07754932255237496, 'depth': 5, 'l2_leaf_reg': 8.895850372170163, 'bagging_temperature': 0.6012806335119553}. Best is trial 4 with value: 5412.338841835868.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:02:15,369] Trial 5 finished with value: 6987.887925346125 and parameters: {'iterations': 645, 'learning_rate': 0.0015289983237041101, 'depth': 5, 'l2_leaf_reg': 3.7383992911704262, 'bagging_temperature': 0.2821959358258662}. Best is trial 4 with value: 5412.338841835868.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:03:11,808] Trial 6 finished with value: 5234.605746347211 and parameters: {'iterations': 1812, 'learning_rate': 0.04872056020241349, 'depth': 7, 'l2_leaf_reg': 9.153367376632207, 'bagging_temperature': 0.241111479095096}. Best is trial 6 with value: 5234.605746347211.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:03:31,458] Trial 7 finished with value: 5352.026121666129 and parameters: {'iterations': 605, 'learning_rate': 0.07709731554261984, 'depth': 7, 'l2_leaf_reg': 3.5268393691746183, 'bagging_temperature': 0.5539404635661076}. Best is trial 6 with value: 5234.605746347211.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:03:54,701] Trial 8 finished with value: 6485.058787554005 and parameters: {'iterations': 1127, 'learning_rate': 0.0024091436731337275, 'depth': 4, 'l2_leaf_reg': 8.037924572395092, 'bagging_temperature': 0.48250920373184947}. Best is trial 6 with value: 5234.605746347211.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:04:32,348] Trial 9 finished with value: 5231.022624998529 and parameters: {'iterations': 1182, 'learning_rate': 0.07562152028459586, 'depth': 7, 'l2_leaf_reg': 8.271285133919728, 'bagging_temperature': 0.9881139235067679}. Best is trial 9 with value: 5231.022624998529.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:05:39,765] Trial 10 finished with value: 5362.636038576299 and parameters: {'iterations': 1257, 'learning_rate': 0.026170671703915023, 'depth': 9, 'l2_leaf_reg': 5.943151611482789, 'bagging_temperature': 0.9759715284327094}. Best is trial 9 with value: 5231.022624998529.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:06:42,505] Trial 11 finished with value: 5341.81645308673 and parameters: {'iterations': 1999, 'learning_rate': 0.024846806458576537, 'depth': 7, 'l2_leaf_reg': 6.53095623670834, 'bagging_temperature': 0.34506608684743956}. Best is trial 9 with value: 5231.022624998529.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:07:44,916] Trial 12 finished with value: 5316.693652089768 and parameters: {'iterations': 1610, 'learning_rate': 0.02823767673852493, 'depth': 8, 'l2_leaf_reg': 1.1949270584141267, 'bagging_temperature': 0.7752104940868232}. Best is trial 9 with value: 5231.022624998529.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:08:14,050] Trial 13 finished with value: 5385.831408871178 and parameters: {'iterations': 1084, 'learning_rate': 0.04612503852804597, 'depth': 6, 'l2_leaf_reg': 9.888817515695797, 'bagging_temperature': 0.030751923287378136}. Best is trial 9 with value: 5231.022624998529.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:09:10,142] Trial 14 finished with value: 5132.974537923892 and parameters: {'iterations': 1452, 'learning_rate': 0.09756856431731578, 'depth': 8, 'l2_leaf_reg': 6.875576395155328, 'bagging_temperature': 0.4258647009997288}. Best is trial 14 with value: 5132.974537923892.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:10:25,516] Trial 15 finished with value: 5114.360092946076 and parameters: {'iterations': 1426, 'learning_rate': 0.09730384926813032, 'depth': 9, 'l2_leaf_reg': 6.7595937133688455, 'bagging_temperature': 0.4382105081728654}. Best is trial 15 with value: 5114.360092946076.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:12:44,217] Trial 16 finished with value: 5443.0397863526705 and parameters: {'iterations': 1455, 'learning_rate': 0.01446540670069461, 'depth': 10, 'l2_leaf_reg': 6.75755460430166, 'bagging_temperature': 0.4235672162438524}. Best is trial 15 with value: 5114.360092946076.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:14:17,068] Trial 17 finished with value: 5091.6226089488855 and parameters: {'iterations': 1696, 'learning_rate': 0.09307372401479128, 'depth': 9, 'l2_leaf_reg': 5.29851212560269, 'bagging_temperature': 0.6722700292508197}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:15:51,415] Trial 18 finished with value: 5409.745725039561 and parameters: {'iterations': 1726, 'learning_rate': 0.015700684545764402, 'depth': 9, 'l2_leaf_reg': 4.660425905200276, 'bagging_temperature': 0.6807929879671659}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:17:07,798] Trial 19 finished with value: 5252.586276925252 and parameters: {'iterations': 1337, 'learning_rate': 0.04192868397494691, 'depth': 9, 'l2_leaf_reg': 5.228172853698964, 'bagging_temperature': 0.8282840597063073}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:19:57,423] Trial 20 finished with value: 5148.107380056494 and parameters: {'iterations': 1675, 'learning_rate': 0.04982191034714931, 'depth': 10, 'l2_leaf_reg': 2.32149933777084, 'bagging_temperature': 0.6224368834206635}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:20:55,030] Trial 21 finished with value: 5139.566248291167 and parameters: {'iterations': 1438, 'learning_rate': 0.09572812047138286, 'depth': 8, 'l2_leaf_reg': 6.966811125376233, 'bagging_temperature': 0.4178987665066286}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:21:48,179] Trial 22 finished with value: 5169.091544698006 and parameters: {'iterations': 966, 'learning_rate': 0.09395760069167228, 'depth': 9, 'l2_leaf_reg': 5.339033003783809, 'bagging_temperature': 0.45903494876663437}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:22:50,096] Trial 23 finished with value: 5185.99921886178 and parameters: {'iterations': 1561, 'learning_rate': 0.061250708320531484, 'depth': 8, 'l2_leaf_reg': 6.189406061732324, 'bagging_temperature': 0.3445146090940195}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:24:03,221] Trial 24 finished with value: 5288.678567014371 and parameters: {'iterations': 1337, 'learning_rate': 0.03476748222461453, 'depth': 9, 'l2_leaf_reg': 7.209734024067195, 'bagging_temperature': 0.5651582645754205}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:25:15,038] Trial 25 finished with value: 5391.293934930817 and parameters: {'iterations': 1786, 'learning_rate': 0.01883889479125705, 'depth': 8, 'l2_leaf_reg': 4.39483853191505, 'bagging_temperature': 0.14125798120138}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:27:29,503] Trial 26 finished with value: 5092.988057191333 and parameters: {'iterations': 1373, 'learning_rate': 0.0988480852859417, 'depth': 10, 'l2_leaf_reg': 6.005577704294214, 'bagging_temperature': 0.371560683973307}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:29:39,501] Trial 27 finished with value: 6498.226268173734 and parameters: {'iterations': 1318, 'learning_rate': 0.001038111867725485, 'depth': 10, 'l2_leaf_reg': 5.813663424269737, 'bagging_temperature': 0.8379986550884667}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:32:20,854] Trial 28 finished with value: 5132.417633468358 and parameters: {'iterations': 1638, 'learning_rate': 0.059506596489986005, 'depth': 10, 'l2_leaf_reg': 4.75328600945508, 'bagging_temperature': 0.3322612961167384}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:34:00,713] Trial 29 finished with value: 5128.796342729506 and parameters: {'iterations': 1842, 'learning_rate': 0.06304840657108748, 'depth': 9, 'l2_leaf_reg': 3.793544903216972, 'bagging_temperature': 0.13523017062958043}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:34:29,496] Trial 30 finished with value: 5462.099811531233 and parameters: {'iterations': 1059, 'learning_rate': 0.03428019062971617, 'depth': 6, 'l2_leaf_reg': 7.440167912073026, 'bagging_temperature': 0.5388532808547251}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:36:10,576] Trial 31 finished with value: 5120.64980012564 and parameters: {'iterations': 1860, 'learning_rate': 0.0650299481925298, 'depth': 9, 'l2_leaf_reg': 3.427972673880256, 'bagging_temperature': 0.10262347277639194}. Best is trial 17 with value: 5091.6226089488855.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:39:20,812] Trial 32 finished with value: 5090.560369855558 and parameters: {'iterations': 1942, 'learning_rate': 0.06504615650610965, 'depth': 10, 'l2_leaf_reg': 2.8309483310103065, 'bagging_temperature': 0.08220447184794222}. Best is trial 32 with value: 5090.560369855558.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:42:36,180] Trial 33 finished with value: 5036.780593884484 and parameters: {'iterations': 1983, 'learning_rate': 0.09434483707156406, 'depth': 10, 'l2_leaf_reg': 2.542819560694613, 'bagging_temperature': 0.23798239433578128}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:45:52,759] Trial 34 finished with value: 5531.659854590207 and parameters: {'iterations': 1992, 'learning_rate': 0.007500111758731959, 'depth': 10, 'l2_leaf_reg': 2.50365356593584, 'bagging_temperature': 0.23607894905148263}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:49:01,418] Trial 35 finished with value: 5158.227101556422 and parameters: {'iterations': 1918, 'learning_rate': 0.039317935861051964, 'depth': 10, 'l2_leaf_reg': 1.0025622091932316, 'bagging_temperature': 0.0007320094048899606}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:51:49,968] Trial 36 finished with value: 5773.393025650923 and parameters: {'iterations': 1724, 'learning_rate': 0.004017417739705932, 'depth': 10, 'l2_leaf_reg': 2.5192800824168295, 'bagging_temperature': 0.08278635067523499}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:54:56,875] Trial 37 finished with value: 5070.6268197588215 and parameters: {'iterations': 1907, 'learning_rate': 0.07330516681063456, 'depth': 10, 'l2_leaf_reg': 2.134097333673803, 'bagging_temperature': 0.17705208523019764}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:58:03,091] Trial 38 finished with value: 5107.718342322174 and parameters: {'iterations': 1890, 'learning_rate': 0.05522731271620711, 'depth': 10, 'l2_leaf_reg': 1.7914447415465515, 'bagging_temperature': 0.18956732887065808}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 16:59:50,607] Trial 39 finished with value: 5451.2314036211665 and parameters: {'iterations': 1952, 'learning_rate': 0.011687971116711294, 'depth': 9, 'l2_leaf_reg': 2.9686709797642434, 'bagging_temperature': 0.18608552839429707}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 17:02:46,949] Trial 40 finished with value: 5073.783738223915 and parameters: {'iterations': 1790, 'learning_rate': 0.07765896300195163, 'depth': 10, 'l2_leaf_reg': 1.7346405315350668, 'bagging_temperature': 0.27789570093153004}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 17:05:40,515] Trial 41 finished with value: 5072.497621231461 and parameters: {'iterations': 1765, 'learning_rate': 0.0734313175834843, 'depth': 10, 'l2_leaf_reg': 1.5020950533493265, 'bagging_temperature': 0.2630091201347615}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 17:08:32,098] Trial 42 finished with value: 5085.867749911262 and parameters: {'iterations': 1749, 'learning_rate': 0.07179303347941321, 'depth': 10, 'l2_leaf_reg': 1.7265473485531482, 'bagging_temperature': 0.2485726603540114}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 17:11:26,687] Trial 43 finished with value: 5085.323917241995 and parameters: {'iterations': 1772, 'learning_rate': 0.07088599060773361, 'depth': 10, 'l2_leaf_reg': 1.724932259163144, 'bagging_temperature': 0.2705740178636292}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 17:14:01,968] Trial 44 finished with value: 5088.248637289046 and parameters: {'iterations': 1569, 'learning_rate': 0.079359325635926, 'depth': 10, 'l2_leaf_reg': 1.6235699092362053, 'bagging_temperature': 0.29921843423643174}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 17:14:36,303] Trial 45 finished with value: 5489.91594303237 and parameters: {'iterations': 1795, 'learning_rate': 0.03021698747763829, 'depth': 4, 'l2_leaf_reg': 1.9346930599926155, 'bagging_temperature': 0.2817797853336122}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 17:17:38,225] Trial 46 finished with value: 5129.0566258051 and parameters: {'iterations': 1839, 'learning_rate': 0.04920530132259153, 'depth': 10, 'l2_leaf_reg': 1.3841776649422137, 'bagging_temperature': 0.21890170114325538}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 17:20:46,383] Trial 47 finished with value: 5063.3585486776265 and parameters: {'iterations': 1893, 'learning_rate': 0.07986671166497598, 'depth': 10, 'l2_leaf_reg': 2.065028281641787, 'bagging_temperature': 0.16129118339660242}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 17:21:30,641] Trial 48 finished with value: 6216.333964106783 and parameters: {'iterations': 761, 'learning_rate': 0.0031310670674727643, 'depth': 9, 'l2_leaf_reg': 2.1537712725706797, 'bagging_temperature': 0.14037069906424982}. Best is trial 33 with value: 5036.780593884484.\n",
      "C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\23150180.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 17:22:21,275] Trial 49 finished with value: 5175.2311113931 and parameters: {'iterations': 1918, 'learning_rate': 0.07950688480683578, 'depth': 6, 'l2_leaf_reg': 3.243862052162555, 'bagging_temperature': 0.18475557193913045}. Best is trial 33 with value: 5036.780593884484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparÃ¡metros: {'iterations': 1983, 'learning_rate': 0.09434483707156406, 'depth': 10, 'l2_leaf_reg': 2.542819560694613, 'bagging_temperature': 0.23798239433578128}\n",
      "Root Mean Squared Error CatBoost (modelo ajustado): 5057.267510624712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['build_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train_train, X_train_validation, y_train_train, y_train_validation = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 25% of 80% is 20% of the total\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest values for the hyperparameters\n",
    "    iterations = trial.suggest_int('iterations', 500, 2000)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 0.1)\n",
    "    depth = trial.suggest_int('depth', 4, 10)\n",
    "    l2_leaf_reg = trial.suggest_float('l2_leaf_reg', 1.0, 10.0)\n",
    "    bagging_temperature = trial.suggest_float('bagging_temperature', 0.0, 1.0)\n",
    "    \n",
    "    # Create the CatBoost model with the suggested hyperparameters\n",
    "    catboost_model = CatBoostRegressor(\n",
    "        iterations=iterations,\n",
    "        learning_rate=learning_rate,\n",
    "        depth=depth,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        bagging_temperature=bagging_temperature,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    catboost_model.fit(X_train_train, y_train_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred_val = catboost_model.predict(X_train_validation)\n",
    "    \n",
    "    # Calculate the RMSE on the validation set\n",
    "    rmse = mean_squared_error(y_train_validation, y_pred_val, squared=False)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Create an Optuna study to minimize RMSE\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "# Train the model with the best hyperparameters on the original full training set\n",
    "best_catboost_model = CatBoostRegressor(**best_params, random_state=42, verbose=0)\n",
    "best_catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the best model on the test set\n",
    "y_pred_best = best_catboost_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "rmse_best = mean_squared_error(y_test, y_pred_best, squared=False)\n",
    "print(f\"Root Mean Squared Error CatBoost (tuned model): {rmse_best}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-13 19:12:56,645] A new study created in memory with name: no-name-9bd57ba5-0aed-4a53-9663-7f4d1c04004e\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 19:15:00,543] Trial 0 finished with value: 7313.929923720392 and parameters: {'n_estimators': 884, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 0 with value: 7313.929923720392.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 19:15:36,158] Trial 1 finished with value: 7508.545435191777 and parameters: {'n_estimators': 306, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 0 with value: 7313.929923720392.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 20:04:58,445] Trial 2 finished with value: 6241.7001646774415 and parameters: {'n_estimators': 644, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 2 with value: 6241.7001646774415.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 20:06:17,206] Trial 3 finished with value: 7594.256849399809 and parameters: {'n_estimators': 763, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 2 with value: 6241.7001646774415.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 20:07:28,794] Trial 4 finished with value: 7164.767646152628 and parameters: {'n_estimators': 443, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 6241.7001646774415.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 20:09:48,889] Trial 5 finished with value: 6776.188165209958 and parameters: {'n_estimators': 522, 'max_depth': 29, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 2 with value: 6241.7001646774415.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 20:16:40,571] Trial 6 finished with value: 6104.290024974263 and parameters: {'n_estimators': 873, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 6 with value: 6104.290024974263.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 20:17:29,949] Trial 7 finished with value: 7588.5690134209335 and parameters: {'n_estimators': 476, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 6 with value: 6104.290024974263.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 20:25:18,841] Trial 8 finished with value: 5908.465801841356 and parameters: {'n_estimators': 792, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 8 with value: 5908.465801841356.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 20:26:24,116] Trial 9 finished with value: 7947.420682645441 and parameters: {'n_estimators': 973, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 8 with value: 5908.465801841356.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 21:15:01,042] Trial 10 finished with value: 5524.945757782166 and parameters: {'n_estimators': 217, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 10 with value: 5524.945757782166.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 21:37:17,516] Trial 11 finished with value: 5556.408426527704 and parameters: {'n_estimators': 100, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 10 with value: 5524.945757782166.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 22:02:29,142] Trial 12 finished with value: 5533.340268138133 and parameters: {'n_estimators': 116, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 10 with value: 5524.945757782166.\n",
      "c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2024-10-13 22:24:39,570] Trial 13 finished with value: 5533.212909620049 and parameters: {'n_estimators': 103, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 10 with value: 5524.945757782166.\n",
      "[W 2024-10-13 23:11:59,817] Trial 14 failed with parameters: {'n_estimators': 268, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 7, 'max_features': None} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joseb\\AppData\\Local\\Temp\\ipykernel_17380\\3123494272.py\", line 32, in objective\n",
      "    rf_model.fit(X_train_train, y_train_train)\n",
      "  File \"c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 192, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"c:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "KeyboardInterrupt\n",
      "[W 2024-10-13 23:11:59,825] Trial 14 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Crear el estudio de Optuna\u001b[39;00m\n\u001b[0;32m     43\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Obtener los mejores hiperparÃ¡metros\u001b[39;00m\n\u001b[0;32m     47\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[8], line 32\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     22\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\n\u001b[0;32m     23\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,\n\u001b[0;32m     24\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39mmax_depth,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo con el conjunto de entrenamiento\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Realizar predicciones en el conjunto de validaciÃ³n\u001b[39;00m\n\u001b[0;32m     35\u001b[0m y_pred_val \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_train_validation)\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\joseb\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['build_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train_train, X_train_validation, y_train_train, y_train_validation = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest values for the hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 4, 30)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])  # Adjustment here\n",
    "\n",
    "    # Create the RandomForest model with the suggested hyperparameters\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    rf_model.fit(X_train_train, y_train_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred_val = rf_model.predict(X_train_validation)\n",
    "    \n",
    "    # Calculate RMSE on the validation set\n",
    "    rmse = mean_squared_error(y_train_validation, y_pred_val, squared=False)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Create an Optuna study for minimizing RMSE\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "# Train the model with the best hyperparameters on the full original training set\n",
    "best_rf_model = RandomForestRegressor(**best_params, random_state=42)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the best model on the test set\n",
    "y_pred_best = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse_best = mean_squared_error(y_test, y_pred_best, squared=False)\n",
    "print(f\"Root Mean Squared Error Random Forest (tuned model): {rmse_best}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
